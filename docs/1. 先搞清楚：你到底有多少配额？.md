有什么能减少 SP-API 返回 429 错误的方法吗？

###### ChatGPT 说：

简单说：429 在 SP-API 里基本就是——**你超额了，桶里没 token 了**，所以想“减少 429”，本质是两件事：

1. 正确读懂自己的配额（rate & burst），
2. 让你的调用节奏去适配它，而不是硬顶。

我分几块讲，尽量贴近你现在的 ASIN 监控项目来讲。

---

## 1. 先搞清楚：你到底有多少配额？

SP-API 用的是 **token bucket（令牌桶）** 算法：每个 operation 有「补充速率（rate, 次/秒）」和「桶容量（burst, 一次能瞬间用多少）」；每次请求消耗 1 个 token，桶空了就会 429。[Cleo+1](https://support.cleo.com/hc/en-us/articles/5458160483095-API-Related-Information-AMP-SP-API?utm_source=chatgpt.com)

官方说明：

- 多数 SP-API 是 **标准 usage plan**，每个接口在文档里有默认的 Rate/Burst；但实际给某个卖家可能比默认高或低。[Amazon Shipping](https://developer-docs.shipping.amazon.com/apis/docs/usage-plans-and-rate-limits-in-the-sp-api?utm_source=chatgpt.com)
- 每次调用会尽量在响应头里带上 `x-amzn-RateLimit-Limit`，告诉你这次请求用的是多少 **requests/second**（这个值是你当前账号+应用对该 operation 的实际限额，不包含其它 usage plan 的叠加限制）。[亚马逊开发者文档+1](https://developer-docs.amazon.com/sp-api/docs/services-api-rate-limits?utm_source=chatgpt.com)

**建议你先做两件事：**

1. **在代码里把所有 SP-API 响应头打印/记录下来**，尤其是：
   - `x-amzn-RateLimit-Limit`
   - `x-amzn-RequestId`
   - 429 时返回 body 里的 `code`（通常是 `QuotaExceeded` / `TooManyRequests`）。
2. 对每个你常用的 operation（比如 Catalog Items 2022-04-01、Listings、Reports 等），大致记住它的：
   - rate（比如 2 req/s、0.0167 req/s 这种鬼畜数值）
   - burst（一次能瞬间打几下）

这样你才知道自己**理论上能打多快**，而不是凭感觉。

---

## 2. 在代码里做一个“统一限流层”，别到处裸调

如果你在各个 service 里随手 `callSpApi()`，同时开多个 worker / 多进程，很容易所有请求一起冲到 Amazon 那边，直接 429。

**更稳的做法**：做一个**统一的“SP-API 调度器/队列”**，所有请求都排队经过它，由它控制“节奏”。

### 核心思路

- 每种 operation（例：`catalogItems.getCatalogItem`、`listingsItems.putListingsItem`…）维护一套：
  - `rate` = 每秒最多多少；
  - `burst` = 同时 / 短时间最多多少。
- 所有要打 SP-API 的地方，只是把“我要调用什么 + 参数”丢进队列，不真的直接发 HTTP。
- 调度器按 operation 的限额，按节奏“吐”请求。

如果你是 Node.js，可以：

- 用自己写的简单节流：基于 `setInterval` + 队列；
- 或者用库（比如 `bottleneck` 之类的限流库）实现“每个 endpoint 一个 limiter”。

伪代码示例（概念上）：

```
// 每个 operation 一条队列 + 配额配置
const queues = {
  getCatalogItem: {
    rate: 1,      // 1 req/sec
    burst: 2,     // 瞬时最多 2
    queue: [],
    running: 0,
  },
  // ...别的 operation
};

async function schedule(operation, task) {
  const q = queues[operation];
  return new Promise((resolve, reject) => {
    q.queue.push({ task, resolve, reject });
  });
}

// 定时器按节奏从队列里取任务执行
setInterval(() => {
  Object.values(queues).forEach(runQueue);
}, 100); // 每 100ms 看一次

function runQueue(q) {
  // 根据 burst / rate 控制并发和出队速度
  while (q.running < q.burst && q.queue.length > 0) {
    const { task, resolve, reject } = q.queue.shift();
    q.running++;
    task()
      .then(resolve)
      .catch(reject)
      .finally(() => q.running--);
  }
}
```

然后你所有的业务里都只写：

```
await schedule('getCatalogItem', () => callSpApi(...));
```

**好处：**

- 所有调用集中管理，你以后要调慢/调快，只改一处配置；
- 很容易根据日志微调每个 operation 的速率，直到几乎不再 429。

---

## 3. 碰到 429 时的“正确姿势”：别硬刚，遵命睡一觉再来

429 不是“异常情况”，而是你“超额提醒”。Amazon 和 AWS 官方建议通用做法是：**遵守 Retry-After + 指数退避（exponential backoff）**。[AWS 文档+1](https://docs.aws.amazon.com/partner-central/latest/APIReference/quotas.html?utm_source=chatgpt.com)

建议流程：

1. 收到 429 时：
   - 如果响应头有 `Retry-After`：
     - **严格等待这个秒数**再重试；
   - 如果没有：
     - 使用一个你自己设定的退避策略，比如：
       - 第一次 429：随机等待 1~2 秒；
       - 第二次同一 operation 又 429：等待 3~5 秒；
       - 再 429：等待 10~20 秒，并把该 operation 的基础速率调低一点。
2. **重试次数要有限制**，比如最多 3 次，仍然 429 就记日志+告警，不要无限循环。
3. 确保你重试的请求是 **幂等** 的（或者你能接受重复执行），否则可能造成重复创建/更新。

很多第三方中间件 / 数据管道（比如 Openbridge 等）也是采取更保守的请求策略 +重试机制来尽量避免 429。[docs.openbridge.com](https://docs.openbridge.com/en/articles/4895388-amazon-selling-partner-api-data-feed-limits-errors-and-constraints?utm_source=chatgpt.com)

---

## 4. 从业务侧“减少调用量”——比调限流更有效

如果你现在是“有多少 ASIN 就每 X 分钟全量打一次 Catalog”，非常容易撞到限额，尤其是像 Reports 这种 rate 只有 0.0167 req/s 的接口。[GitHub](https://github.com/jlevers/selling-partner-api/issues/442?utm_source=chatgpt.com)

可以从几方面减负：

### 4.1 缓存 + 增量

- **静态信息**（比如大部分 catalog 元数据、图片、尺寸）：一天甚至几天更新一次就够了，没必要每小时刷。
- **状态信息**（比如变体关系、上架/下架状态）：
  - 可以**按优先级分层**：
    - 最近销量高 / 有异常历史 / 正在投广告的 ASIN：高频刷新；
    - 长尾 ASIN：低频刷新。
- 把每次的响应都写到 MySQL 或 Redis，后端视图直接从你自己的库查，只有“超出 TTL”的记录才去打 SP-API。

正经的最佳实践都会建议你**大量依靠缓存 + 增量更新**，而不是把 SP-API 当数据库用。[docs.openbridge.com+1](https://docs.openbridge.com/en/articles/4895388-amazon-selling-partner-api-data-feed-limits-errors-and-constraints?utm_source=chatgpt.com)

### 4.2 使用 **批量（batch）接口**，能批就别单打独斗

部分 API 提供了 batch 版本（例如某些 Product Pricing、Featured Offer 相关的 batch operation），可以一次传多个 ASIN，消耗的 token 只按“调用次数”计，不按 ASIN 数计。[亚马逊开发者文档+1](https://developer-docs.amazon.com/sp-api/lang-ja_JP/docs/sp-api-release-notes?ld=NSGoogle%2F&utm_source=chatgpt.com)

你现在做的是 ASIN 监控：

- 如果你用到的是那些有 batch 版本的接口，尽量凑成一批批发；
- 虽然 Catalog Items 这块目前 batch 能力有限，但其他地方（如价格、库存、报告）能批的都批。

### 4.3 把“轮询”改成“事件驱动”（能用 Notifications / Reports 就用）

- 例如订单变化，不要每 30 秒去 `getOrders`；改用 **Notifications API 订阅 ORDER_CHANGE**，然后只在有通知时再去拉详情。[亚马逊开发者文档+1](https://developer-docs.amazon.com/sp-api/docs/app-integrations-api-v2024-04-01-model?utm_source=chatgpt.com)
- 类似的，一些大数据量查询本来就建议用 **Reports API** 异步导出，而不是靠频繁 direct 查询。[GitHub+1](https://github.com/jlevers/selling-partner-api/issues/442?utm_source=chatgpt.com)

变体监控这块 Amazon 目前没有“变体被拆通知”，但你可以：

- 把“全量体检”做成低频（例如每天 1~2 次）；
- 其它时间只对“重点 ASIN 列表”做高频检查。

### 4.4 去重：不要重复提交同一内容

Amazon 官方样例里也提醒：重复提交完全相同的 listing 数据会浪费配额，还会拖慢真正重要更新的处理。[GitHub](https://github.com/amzn/selling-partner-api-samples/discussions/109?ld=ASXXSPAPIDirect&pageName=US%3ASPDS%3ASPAPI-solution-listing&utm_source=chatgpt.com)

所以：

- 对你要提交的 payload 做一个哈希；
- 如果最近 N 分钟内你已经给同一个 SKU + 同样内容提交过，就不要再打。

---

## 5. 一些容易被忽略的坑

### 5.1 限额是“按账号”算，不是你多注册几个 app 就能翻倍

官方说明，很多限额是 **per selling-partner account** 而不是 per app。多个 app 共用同一个卖家账号时，是共享 usage plan 的。[Stack Overflow+1](https://stackoverflow.com/questions/70379004/amazon-sp-api-call-limit-multiple-apps?utm_source=chatgpt.com)

所以：

- 不要指望“再建一个 SP-API 应用就能多一倍配额”；
- 要统一规划所有内部工具对同一卖家账号的请求量。

### 5.2 “一直被频繁 throttled” 不会让 Amazon 自动给你涨配额

Usage Plan 文档里说得很直接：如果你的应用一直被 throttling，说明调用模式没有对齐配额，而不是应该涨配额。一般不会因为你 429 多就给你提限。[spapi.cyou](https://spapi.cyou/en/use-other/usage-plans-and-rate-limits-in-the-sp-api.html?utm_source=chatgpt.com)

所以你能做的是：**改模式**、**做缓存**、**拉长周期**，而不是“撞多几次看看会不会给我放宽”。

### 5.3 Sandbox 的限额跟生产不一样，别拿它当准

Sandbox 环境的 rate limit 是统一的，主要用于测试 429 处理逻辑；真实的 usage plan 得看生产环境返回的 header。[Amazon Shipping+1](https://developer-docs.shipping.amazon.com/apis/docs/usage-plans-and-rate-limits-in-the-sp-api?utm_source=chatgpt.com)

---

## 6. 结合你现在的 ASIN 监控项目，给一套落地建议

根据你之前说的：

- 后端是 Node.js + Express；
- 有一个定时任务去批量检查 ASIN 变体关系；
- 目前已经在 Feishu 发配额信息 + 报警。

你可以按下面这套来改：

1. **写一个 `spApiClient.js`，里面封装：**
   - 统一的 HTTP 客户端；
   - 对应 operation 的限流配置；
   - 429 的重试 + backoff；
   - 把 `x-amzn-RateLimit-Limit`、429 错误信息打日志（可以顺便发一条飞书）。
2. **在定时任务里改调用方式：**
   - 把“要检查的 ASIN 列表 + operation 名称”丢进调度器；
   - 根据 ASIN 的优先级分批（热销/问题 ASIN 小批高频，其它大批低频）；
   - 对每天的“全量变体体检”设成夜间低峰执行，慢慢跑，不要和白天的实时监控抢配额。
3. **加缓存表，比如 `monitor_snapshots`：**
   - 对于上次检查时间 < X 分钟的 ASIN，直接用缓存，不打 SP-API；
   - 只对“缓存过期”或“上次检查有异常”的 ASIN 重新打接口。
4. **定期用 SQL 看看：**
   - 各 endpoint 每小时的调用量；
   - 429 的次数和时间段；
   - 根据结果去调整每个 operation 的 rate / 调度策略。

这样做下来，一般能把 429 降到「偶尔才出现，而不是刷屏」，而且就算偶发 429，也能自动按 Retry-After + backoff 稳定恢复。
